\section{General reductions}

Left folds offer a great guarantee of strict left-to-right evaluation, allowing high flexibility for the fold operation.

However, when we work with operations that are associative $op(a, op(b,c)) == op(op(a,b),c)$ and commutative $op(a,b) == op(b,a)$, it really doesn’t matter what permutation of elements and order of operations we evaluate, we will always arrive at the same result.

This is why with the parallel support in C++17, we also received a batch of generalised reduction algorithms that reduce elements in unspecified order and permutation.

\subsection{\texorpdfstring{\cpp{std::reduce}}{\texttt{std::reduce}}}

The \cpp{std::reduce} algorithm is a generalised version of \cpp{std::accumulate}. That is, it reduces a range by applying the provided accumulation operation to the elements in unspecified order and permutation.

\cppversions{\texttt{reduce}}{\CC17}{\CC20}{\CC17}{N/A}
\constraints{\texttt{input\_range}}{\texttt{forward\_range}}{\texttt{std::plus<>()}}{\texttt{binary\_functor}}

Note that while we have access to a sequenced execution policy (\cpp{std::execution::seq}), this does not make \cpp{std::reduce} sequenced in a left-fold sense.

\begin{box-note}
\footnotesize Example of using \cpp{std::reduce} with and without an execution policy.
\tcblower
\cppfile{code_examples/algorithms/reduce_code.h}
\end{box-note}

On top of the \cpp{std::accumulate} equivalents, we get one more overload that does away with the initial accumulator value, which removes the potential for using the wrong literal. Instead, the accumulator will be of the type of the ranges’ elements and will be value initialised.

\begin{box-note}
\footnotesize Example of using \cpp{std::reduce} without specifying the initial value of the accumulator.
\tcblower
\cppfile{code_examples/algorithms/reduce_noinit_code.h}
\end{box-note}

The initial value of the accumulator will be “Quack” (line 2). Adding the other two ducks (line 8), we end up with “QuackQuackQuack”.

\subsection{\texorpdfstring{\cpp{std::transform_reduce}}{\texttt{std::transform\_reduce}}}

The \cpp{std::transform_reduce} algorithm is the generalised counterpart to \cpp{std::inner_product}. On top of the two-range variant, the algorithm also provides a unary overload.

\cppversions{\texttt{transform\_reduce}}{\CC17}{\CC20}{\CC17}{N/A}
\constraints{\texttt{input\_range}}{\texttt{forward\_range}}{N/A}{\texttt{(binary\_functor, unary\_functor)}}
\constraints{\texttt{(input\_range, input\_iterator)}}{\texttt{(forward\_range, forward\_iterator)}}{\texttt{(std::plus<>(), std::multiplies<>())}}{\texttt{(binary\_functor, binary\_functor)}}

\begin{box-note}
\footnotesize Example of using the unary version of \cpp{std::transform_reduce} to calculate a sum of squares and the binary version to calculate a sum of elements multiplied by coefficients.
\tcblower
\cppfile{code_examples/algorithms/transform_reduce_code.h}
\end{box-note}

\subsection{\texorpdfstring{\cpp{std::inclusive_scan}, \cpp{std::exclusive_scan}}{\texttt{std::inclusive\_scan}, \texttt{std::exclusive\_scan}}}

The \cpp{std::inclusive_scan} is a generalised version of \cpp{std::partial_sum}. On top of that, we also have access to \cpp{std::exclusive_scan}.

For \cpp{std::inclusive_scan}, the nth generated element is the sum of the first n source elements. For \cpp{std::exclusive_scan}, the nth element is the sum of the first n-1 source elements.

\cppversions{\texttt{inclusive\_scan}}{\CC17}{\CC20}{\CC17}{N/A}
\cppversions{\texttt{exclusive\_scan}}{\CC17}{\CC20}{\CC17}{N/A}

\constraints{\texttt{input\_range -> output\_iterator}}{\texttt{forward\_range -> forward\_iterator}}{\texttt{std::plus<>()}}{\texttt{binary\_functor}}

\begin{box-note}
\footnotesize Example of using \cpp{std::inclusive_scan}.
\tcblower
\cppfile{code_examples/algorithms/inclusive_scan_code.h}
\end{box-note}

Consequently, because the first element generated by \cpp{std::exclusive_scan} is the sum of zero elements, we must specify an initial value of the accumulator, which will be the value of the first generated element.



\subsection{\texorpdfstring{\cpp{std::transform_inclusive_scan},\newline\cpp{std::transform_exclusive_scan}}{\texttt{std::transform\_inclusive\_scan},\newline \texttt{std::transform\_exclusive\_scan}}}


In C++17, along with the other parallel algorithms, we have received reduce, inclusive\_scan and exclusive\_scan, which are relaxed versions of accumulate, inner\_product and partial\_sum that require an associative and commutative operation to produce deterministic results.

\subsection{exclusive\_scan, inclusive\_scan, transform\_exclusive\_scan, transform\_inclusive\_scan}

The last left-fold algorithm without a parallel counterpoint is partial\_sum.

\cppversions{\texttt{exclusive\_scan, inclusive\_scan}}{\CC17}{\CC20}{\CC17}{N/A}

\constraints{\texttt{input\_range -> output\_iterator}}{\texttt{forward\_range -> forward\_iterator}}{\texttt{std::plus<>()}}{\texttt{binary\_functor}}

The 1:1 counterpoint to partial\_sum is inclusive\_scan, which follows the same logic: nth generated element is the sum of the first n source elements. On top of that, we also get exclusive\_scan, where the nth generated element is the sum of the first n-1 source elements. Or: the inclusive version includes the element on the nth position, and the exclusive version excludes it.



\begin{box-note}
\begin{cppcode}
std::vector<int> src{1, 2, 3, 4, 5, 6};
{
    std::vector<int> out;
    std::inclusive_scan(src.begin(), src.end(), std::back_inserter(out));
    // out == {1, 3, 6, 10, 15, 21}
    std::inclusive_scan(src.begin(), src.end(), out.begin(), std::multiplies<>{}, 1);
    // out == {1, 2, 6, 24, 120, 720}
}
{
    std::vector<int> out;
    std::exclusive_scan(src.begin(), src.end(), std::back_inserter(out), 0);
    // out == {0, 1, 3, 6, 10, 15}
    std::exclusive_scan(src.begin(), src.end(), out.begin(), 1, std::multiplies<>{});
    // out == {1, 1, 2, 6, 24, 120}
}
\end{cppcode}
\end{box-note}

\cppversions{\texttt{transform\_inclusive\_scan, transform\_exclusive\_scan}}{\CC17}{\CC20}{\CC17}{N/A}

\constraints{\texttt{input\_range -> output\_iterator}}{\texttt{forward\_range -> forward\_iterator}}{N/A}{\texttt{(binary\_functor, unary\_functor)}}

The transform variants of inclusive\_scan and exclusive\_scan apply a unary transformation to each element. Unfortunately, we do not get an overload that would operate on two input ranges (in the style of inner\_product).

\begin{box-note}
\begin{cppcode}
std::vector<int> data{-10, 3, -2, 5, 6};

std::vector<int> out1;
std::inclusive_scan(data.begin(), data.end(), std::back_inserter(out1), 
                    std::plus<>{});
// out1 == {-10, -7, -9, -4, 2}

std::vector<int> out2;
std::transform_inclusive_scan(data.begin(), data.end(), std::back_inserter(out2), 
                              std::plus<>{}, [](int v) { return std::abs(v); });
// out2 == {10, 13, 15, 20, 26}
\end{cppcode}
\end{box-note}

