\section{General reductions}

Left folds offer a great guarantee of strict left-to-right evaluation, allowing high flexibility for the fold operation.

However, when we work with operations that are associative $op(a, op(b,c)) == op(op(a,b),c)$ and commutative $op(a,b) == op(b,a)$, it really doesn’t matter what permutation of elements and order of operations we evaluate, we will always arrive at the same result.

This is why with the parallel support in C++17, we also received a batch of generalized reduction algorithms that reduce elements in unspecified order and permutation.

\subsection{\texorpdfstring{\cpp{std::reduce}}{\texttt{std::reduce}}}

The \cpp{std::reduce} algorithm is a generalized version of \cpp{std::accumulate}. That is, it reduces a range by applying the provided accumulation operation to the elements in unspecified order and permutation.

\cppversions{\texttt{reduce}}{\CC17}{\CC20}{\CC17}{N/A}
\constraints{\texttt{input\_range}}{\texttt{forward\_range}}{\texttt{std::plus<>()}}{\texttt{binary\_functor}}

Note that while we have access to a sequenced execution policy (\cpp{std::execution::seq}), this does not make \cpp{std::reduce} sequenced in a left-fold sense.

\begin{box-note}
\footnotesize Example of using \cpp{std::reduce} with and without an execution policy.
\tcblower
\cppfile{code_examples/algorithms/reduce_code.h}
\end{box-note}

On top of the std::accumulate equivalents, we get one more overload that does away with the initial accumulator value, which removes the potential for using the wrong literal. Instead, the accumulator will be of the type of the ranges’ elements and will be value initialised.

\begin{box-note}
\footnotesize Example of using \cpp{std::reduce} without specifying the initial value of the accumulator.
\tcblower
\cppfile{code_examples/algorithms/reduce_noinit_code.h}
\end{box-note}

The initial value of the accumulator will be “Quack”. Adding the other two ducks, we end up with “QuackQuackQuack”.

\subsection{reduce, transform\_reduce}

In C++17, along with the other parallel algorithms, we have received reduce, inclusive\_scan and exclusive\_scan, which are relaxed versions of accumulate, inner\_product and partial\_sum that require an associative and commutative operation to produce deterministic results.

On top of the accumulate equivalents, we get one more overload that does away with the initial accumulator value, reducing the aforementioned numerical problems.

\begin{box-note}
\begin{cppcode}
std::vector<double> data{1.1, 2.2, 3.3, 4.4, 5.5};
auto result = reduce(data.begin(), data.end());
// result == 16.5
\end{cppcode}
\end{box-note}

The accumulator will be of the type of the ranges’ elements and will be value initialised. So, the accumulator will be type double and initialised to zero in this example.

Of course, this also works for custom types:

\begin{box-note}
\begin{cppcode}
struct Duck {
    std::string sound = "Quack";
    friend Duck operator+(const Duck& left, const Duck& right) {
        return {left.sound+right.sound};
    }
};

std::vector<Duck> data(2, Duck{});
Duck final_duck = std::reduce(data.begin(), data.end());
// final_duck.sound == "QuackQuackQuack"
\end{cppcode}
\end{box-note}

The initial value of the accumulator will be “Quack”. Adding the other two ducks, we end up with “QuackQuackQuack”.

The counterpart to inner\_product is transform\_reduce, with additional overloads for the unary case (single range).

\cppversions{\texttt{transform\_reduce}}{\CC17}{\CC20}{\CC17}{N/A}

Unary version:

\constraints{\texttt{input\_range}}{\texttt{forward\_range}}{N/A}{\texttt{(binary\_functor, unary\_functor)}}

Binary version:

\constraints{\texttt{(input\_range, input\_iterator)}}{\texttt{(forward\_range, forward\_iterator)}}{\texttt{(std::plus<>(), std::multiplies<>())}}{\texttt{(binary\_functor, binary\_functor)}}

Same as reduce, provided functors must not modify the elements or invalidate iterators. In addition, the reduction functor must be associative and commutative.

\begin{box-note}
\begin{cppcode}
std::vector<int> data{1, 2, 3, 4, 5};
auto sum_of_squares = std::transform_reduce(data.begin(), data.end(), 0, 
                                            std::plus<>{}, [](int v) { return v*v; });
// sum_of_squares == 55

std::vector<int> coef{1, -1, 1, -1, 1};
auto result = std::transform_reduce(data.begin(), data.end(), coef.begin(), 0);
// result == 1*1 + 2*(-1) + 3*1 + 4*(-1) + 5*1 == 3
\end{cppcode}
\end{box-note}

\subsection{exclusive\_scan, inclusive\_scan, transform\_exclusive\_scan, transform\_inclusive\_scan}

The last left-fold algorithm without a parallel counterpoint is partial\_sum.

\cppversions{\texttt{exclusive\_scan, inclusive\_scan}}{\CC17}{\CC20}{\CC17}{N/A}

\constraints{\texttt{input\_range -> output\_iterator}}{\texttt{forward\_range -> forward\_iterator}}{\texttt{std::plus<>()}}{\texttt{binary\_functor}}

The 1:1 counterpoint to partial\_sum is inclusive\_scan, which follows the same logic: nth generated element is the sum of the first n source elements. On top of that, we also get exclusive\_scan, where the nth generated element is the sum of the first n-1 source elements. Or: the inclusive version includes the element on the nth position, and the exclusive version excludes it.

Consequently, for the exclusive\_scan algorithm, we must specify an initial value of the accumulator, which will be the value of the first generated element.

\begin{box-note}
\begin{cppcode}
std::vector<int> src{1, 2, 3, 4, 5, 6};
{
    std::vector<int> out;
    std::inclusive_scan(src.begin(), src.end(), std::back_inserter(out));
    // out == {1, 3, 6, 10, 15, 21}
    std::inclusive_scan(src.begin(), src.end(), out.begin(), std::multiplies<>{}, 1);
    // out == {1, 2, 6, 24, 120, 720}
}
{
    std::vector<int> out;
    std::exclusive_scan(src.begin(), src.end(), std::back_inserter(out), 0);
    // out == {0, 1, 3, 6, 10, 15}
    std::exclusive_scan(src.begin(), src.end(), out.begin(), 1, std::multiplies<>{});
    // out == {1, 1, 2, 6, 24, 120}
}
\end{cppcode}
\end{box-note}

\cppversions{\texttt{transform\_inclusive\_scan, transform\_exclusive\_scan}}{\CC17}{\CC20}{\CC17}{N/A}

\constraints{\texttt{input\_range -> output\_iterator}}{\texttt{forward\_range -> forward\_iterator}}{N/A}{\texttt{(binary\_functor, unary\_functor)}}

The transform variants of inclusive\_scan and exclusive\_scan apply a unary transformation to each element. Unfortunately, we do not get an overload that would operate on two input ranges (in the style of inner\_product).

\begin{box-note}
\begin{cppcode}
std::vector<int> data{-10, 3, -2, 5, 6};

std::vector<int> out1;
std::inclusive_scan(data.begin(), data.end(), std::back_inserter(out1), 
                    std::plus<>{});
// out1 == {-10, -7, -9, -4, 2}

std::vector<int> out2;
std::transform_inclusive_scan(data.begin(), data.end(), std::back_inserter(out2), 
                              std::plus<>{}, [](int v) { return std::abs(v); });
// out2 == {10, 13, 15, 20, 26}
\end{cppcode}
\end{box-note}

